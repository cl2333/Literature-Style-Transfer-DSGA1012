{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_raw = open('original_all.txt').read()\n",
    "modern_raw = open('modern_all.txt').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function for processing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(data, sub_list=['ì','î','`', 'ó']):\n",
    "    for sub_char in sub_list:\n",
    "        data = re.sub(sub_char, '', data)\n",
    "        \n",
    "    data = re.sub('í', \"'\", data)\n",
    "    \n",
    "    # Delete empty lines\n",
    "    while ('\\n\\n' in data):\n",
    "        data = re.sub('\\n\\n', '\\n', data)\n",
    "    \n",
    "    # Remove blanks at end of paragraph\n",
    "    while (' \\n' in data):\n",
    "        data = re.sub(' \\n', '\\n', data)\n",
    "        \n",
    "    # Seperate punctuations, insert space before and after \n",
    "    \n",
    "    data = re.sub('([.,!?;:])', r' \\1 ', data)\n",
    "    data = re.sub('\\s{2,}', ' ', data)\n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_all_cleaned = process_text(original_raw)\n",
    "modern_all_cleaned = process_text(modern_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save processed files. (Make sure to delete original ones from directory first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "open('original_all_cleaned.txt', 'w').write(original_all_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "open('modern_all_cleaned.txt', 'w').write(modern_all_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. More cleaning with NLTK (in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yuweiwang/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_corpus = PlaintextCorpusReader(os.getcwd(), 'original_all_cleaned.txt')\n",
    "modern_corpus = PlaintextCorpusReader(os.getcwd(), 'modern_all_cleaned.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total paragraphs in this corpus:', 3269)\n",
      "('Total sentences in this corpus: ', 7656)\n",
      "('First sentence in this corpus: ', [u'It', u'was', u'the', u'best', u'of', u'times', u',', u'it', u'was', u'the', u'worst', u'of', u'times', u',', u'it', u'was', u'the', u'age', u'of', u'wisdom', u',', u'it', u'was', u'the', u'age', u'of', u'foolishness', u',', u'it', u'was', u'the', u'epoch', u'of', u'belief', u',', u'it', u'was', u'the', u'epoch', u'ofincredulity', u',', u'it', u'was', u'the', u'season', u'of', u'Light', u',', u'it', u'was', u'the', u'season', u'of', u'Darkness', u',', u'it', u'wasthe', u'spring', u'of', u'hope', u',', u'it', u'was', u'the', u'winter', u'of', u'despair', u',', u'we', u'had', u'everything', u'before', u'us', u',', u'we', u'had', u'nothing', u'before', u'us', u',', u'we', u'were', u'all', u'going', u'direct', u'to', u'Heaven', u',', u'we', u'were', u'all', u'goingdirect', u'the', u'other', u'wayin', u'short', u',', u'the', u'period', u'was', u'so', u'far', u'like', u'the', u'present', u'period', u',', u'that', u'some', u'of', u'its', u'noisiest', u'authorities', u'insisted', u'on', u'its', u'being', u'received', u',', u'for', u'goodor', u'for', u'evil', u',', u'in', u'the', u'superlative', u'degree', u'of', u'comparison', u'only', u'.'])\n",
      "('Words in this corpus: ', [u'It', u'was', u'the', u'best', u'of', u'times', u',', ...])\n"
     ]
    }
   ],
   "source": [
    "original_para = original_corpus.paras()\n",
    "print(\"Total paragraphs in this corpus:\", len(original_para))\n",
    "\n",
    "original_sent = original_corpus.sents()\n",
    "print(\"Total sentences in this corpus: \", len(original_sent))\n",
    "print(\"First sentence in this corpus: \", original_sent[0])\n",
    "\n",
    "original_word = original_corpus.words()\n",
    "print(\"Words in this corpus: \", original_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check load data function (in progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Shakespear text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_data = open('sample',\"r\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text_rows):\n",
    "\treturn [row.strip().lower().split(' ') for row in text_rows]\n",
    "\n",
    "inputs = preprocess(inp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', 'jumbled', 'confession', 'can', 'only', 'receive', 'a', 'jumbled', 'absolution', '.'], ['i', 'love', 'rich', \"capulet's\", 'daughter', '.'], [\"we're\", 'bound', 'to', 'each', 'other', 'in', 'every', 'possible', 'way', ',', 'except', 'we', 'need', 'you', 'to', 'marry', 'us', '.'], [\"i'll\", 'tell', 'you', 'more', 'later', 'about', 'when', 'and', 'where', 'we', 'met', ',', 'how', 'we', 'fell', 'in', 'love', ',', 'and', 'how', 'we', 'exchanged', 'promises', ',', 'but', 'now', \"i'm\", 'begging', 'you', ':', 'please', ',', 'agree', 'to', 'marry', 'us', 'today', '.'], ['holy', 'saint', 'francis', ',', 'this', 'is', 'a', 'drastic', 'change', '!']]\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 New input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'was', 'the', 'best', 'of', 'times', ',', 'it', 'was', 'the', 'worst', 'of', 'times', ',', 'it', 'was', 'the', 'age', 'of', 'wisdom', ',', 'it', 'was', 'the', 'age', 'of', 'foolishness', ',', 'it', 'was', 'the', 'epoch', 'of', 'belief', ',', 'it', 'was', 'the', 'epoch', 'ofincredulity', ',', 'it', 'was', 'the', 'season', 'of', 'light', ',', 'it', 'was', 'the', 'season', 'of', 'darkness', ',', 'it', 'wasthe', 'spring', 'of', 'hope', ',', 'it', 'was', 'the', 'winter', 'of', 'despair', ',', 'we', 'had', 'everything', 'before', 'us', ',', 'we', 'had', 'nothing', 'before', 'us', ',', 'we', 'were', 'all', 'going', 'direct', 'to', 'heaven', ',', 'we', 'were', 'all', 'goingdirect', 'the', 'other', 'wayin', 'short', ',', 'the', 'period', 'was']\n"
     ]
    }
   ],
   "source": [
    "new_data = open('original_all_cleaned.txt',\"r\").readlines()\n",
    "new_inputs = preprocess(new_data)\n",
    "print(new_inputs[0][0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process splitted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pro_data(input_file, save_name):\n",
    "    open_file = open(input_file).read()\n",
    "    process_file = process_text(open_file)\n",
    "    open(save_name, 'w').write(process_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_data('train.original.para', 'train.original.newpara')\n",
    "pro_data('train.modern.para', 'train.modern.newpara')\n",
    "pro_data('valid.original.para', 'valid.original.newpara')\n",
    "pro_data('valid.modern.para','valid.modern.newpara')\n",
    "pro_data('test.original.para','test.original.newpara')\n",
    "pro_data('test.modern.para','test.modern.newpara')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
